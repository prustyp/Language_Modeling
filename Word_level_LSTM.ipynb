{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from datetime import datetime\n",
    "from nltk import tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import csv\n",
    "import itertools\n",
    "import operator\n",
    "import numpy as np\n",
    "import nltk\n",
    "%matplotlib inline\n",
    "from IPython import display\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load 3 Text Books and Concatenate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text files concatenation \n",
    "filenames = ['A_Journey_to_the_Center_of_the_Earth.txt', 'From_the_Earth_to_the_Moon.txt', 'The_master_of_the_world.txt']\n",
    "with open('/Users/pprusty05/google_drive/Deep_Learning/assignment3/Text_file_for_training.txt', 'w+') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open(fname) as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = open('Text_file_for_training.txt', 'r').read() \n",
    "\n",
    "#print(train_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 5000\n",
    "unknown_token = \"UNKNOWN\"\n",
    "sentence_start_token = \"SENTENCE_START\"\n",
    "sentence_end_token = \"SENTENCE_END\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Text file, tokenize sentences and append sentence start and end token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 13926 sentences.\n"
     ]
    }
   ],
   "source": [
    "with open ('Text_file_for_training.txt', 'r') as f:\n",
    "    \n",
    "    text = f.read()\n",
    "    tokenized_sent = nltk.sent_tokenize(text)\n",
    "    sentences=[x.replace('\\n',' ') for x in tokenized_sent]\n",
    "    sentences = [re.sub('[^a-zA-Z0-9]', ' ', x)for x in tokenized_sent]\n",
    "    sentences = [word.lower() for word in sentences]\n",
    "\n",
    "    #sentences = itertools.chain(*[tokenize.sent_tokenize(x) for x in f])\n",
    "    sentences = [\"%s %s %s\" % (sentence_start_token, x, sentence_end_token) for x in sentences]\n",
    "    \n",
    "print( \"Parsed %d sentences.\" % (len(sentences)))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the sentences into words\n",
    "tokenized_words = [nltk.word_tokenize(sent) for sent in sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claculate word frequency and build index_to_word and word_to_index vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13079 unique words tokens.\n"
     ]
    }
   ],
   "source": [
    "# Count the word frequencies\n",
    "word_freq = nltk.FreqDist(itertools.chain(*tokenized_words))\n",
    "print(\"Found %d unique words tokens.\" % len(word_freq.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 17484, 'SENTENCE_START': 13926, 'SENTENCE_END': 13926, 'of': 9369, 'to': 6171, 'and': 5424, 'a': 4466, 'in': 3619, 'i': 3275, 'was': 2858, ...})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the most common words and build index_to_word and word_to_index vectors\n",
    "vocab = word_freq.most_common(vocabulary_size-1)\n",
    "index_to_word = [x[0] for x in vocab]\n",
    "index_to_word.append(unknown_token)\n",
    "word_to_index = dict([(w,i) for i,w in enumerate(index_to_word)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using vocabulary size 5000.\n",
      "The least frequent word in our vocabulary is 'clamps' and appeared 3 times.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('the', 17484),\n",
       " ('SENTENCE_START', 13926),\n",
       " ('SENTENCE_END', 13926),\n",
       " ('of', 9369),\n",
       " ('to', 6171),\n",
       " ('and', 5424),\n",
       " ('a', 4466),\n",
       " ('in', 3619),\n",
       " ('i', 3275),\n",
       " ('was', 2858)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Using vocabulary size %d.\" % vocabulary_size)\n",
    "print(\"The least frequent word in our vocabulary is '%s' and appeared %d times.\" % (vocab[-1][0], vocab[-1][1]))\n",
    "word_freq.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all words not in our vocabulary with the unknown token\n",
    "for i, sent in enumerate(tokenized_words):\n",
    "    tokenized_words[i] = [w if w in word_to_index else unknown_token for w in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example sentence: 'SENTENCE_START project gutenberg s a journey to the centre of the earth  by jules verne  this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever  SENTENCE_END'\n",
      "\n",
      "Example sentence after Pre-processing: '['SENTENCE_START', 'project', 'gutenberg', 's', 'a', 'journey', 'to', 'the', 'centre', 'of', 'the', 'earth', 'by', 'jules', 'verne', 'this', 'ebook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', 'SENTENCE_END']'\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nExample sentence: '%s'\" % sentences[0])\n",
    "print(\"\\nExample sentence after Pre-processing: '%s'\" % tokenized_words[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XTrain and yTrain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training data\n",
    "XTrain = np.asarray([[word_to_index[w] for w in sent[:-1]] for sent in tokenized_words])\n",
    "yTrain = np.asarray([[word_to_index[w] for w in sent[1:]] for sent in tokenized_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13926,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13926,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "SENTENCE_START to bear with him means to obey and scarcely had his heavy feet resounded within our UNKNOWN UNKNOWN than he shouted for me to attend upon him\n",
      "[1, 4, 1159, 19, 76, 216, 4, 3249, 5, 332, 20, 26, 488, 104, 3250, 226, 34, 4999, 4999, 75, 25, 2649, 27, 47, 4, 4913, 62, 76]\n",
      "\n",
      "y:\n",
      "to bear with him means to obey and scarcely had his heavy feet resounded within our UNKNOWN UNKNOWN than he shouted for me to attend upon him SENTENCE_END\n",
      "[4, 1159, 19, 76, 216, 4, 3249, 5, 332, 20, 26, 488, 104, 3250, 226, 34, 4999, 4999, 75, 25, 2649, 27, 47, 4, 4913, 62, 76, 2]\n"
     ]
    }
   ],
   "source": [
    "# Print an training data example\n",
    "x_example, y_example = XTrain[17], yTrain[17]\n",
    "print (\"x:\\n%s\\n%s\" % (\" \".join([index_to_word[x] for x in x_example]), x_example))\n",
    "print (\"\\ny:\\n%s\\n%s\" % (\" \".join([index_to_word[x] for x in y_example]), y_example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Word-level LSTM RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size,vocab_size = len(train_data), vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants and hyper-params\n",
    "H_size = 10 # Size of the hidden layer\n",
    "T_steps = 10\n",
    "# Number of time steps (length of the sequence) used for training\n",
    "learning_rate = 0.005 # Learning rate\n",
    "weight_sd = 0.1 # Standard deviation of weights for initialization\n",
    "z_size = H_size + vocab_size # Size of concatenate(H, X) vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def dsigmoid(y):\n",
    "    return y * (1 - y)\n",
    "\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "\n",
    "def dtanh(y):\n",
    "    return 1 - y * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "# We use random weights with normal distribution (0, weight_sd) for  tanh  activation function \n",
    "# and (0.5, weight_sd) for  sigmoid  activation function.\n",
    "# Biases are initialized to zeros.\n",
    "class Param:\n",
    "    def __init__(self, name, value):\n",
    "        self.name = name\n",
    "        self.v = value #parameter value\n",
    "        self.d = np.zeros_like(value) #derivative\n",
    "        self.m = np.zeros_like(value) #momentum for AdaGrad\n",
    "        \n",
    "class Parameters:\n",
    "    def __init__(self):\n",
    "        self.W_f = Param('W_f', \n",
    "                         np.random.randn(H_size, z_size) * weight_sd + 0.5)\n",
    "        self.b_f = Param('b_f',\n",
    "                         np.zeros((H_size, 1)))\n",
    "\n",
    "        self.W_i = Param('W_i',\n",
    "                         np.random.randn(H_size, z_size) * weight_sd + 0.5)\n",
    "        self.b_i = Param('b_i',\n",
    "                         np.zeros((H_size, 1)))\n",
    "\n",
    "        self.W_C = Param('W_C',\n",
    "                         np.random.randn(H_size, z_size) * weight_sd)\n",
    "        self.b_C = Param('b_C',\n",
    "                         np.zeros((H_size, 1)))\n",
    "\n",
    "        self.W_o = Param('W_o',\n",
    "                         np.random.randn(H_size, z_size) * weight_sd + 0.5)\n",
    "        self.b_o = Param('b_o',\n",
    "                         np.zeros((H_size, 1)))\n",
    "\n",
    "        #For final layer to predict the next character\n",
    "        self.W_v = Param('W_v',\n",
    "                         np.random.randn(vocab_size, H_size) * weight_sd)\n",
    "        self.b_v = Param('b_v',\n",
    "                         np.zeros((vocab_size, 1)))\n",
    "        \n",
    "    def all(self):\n",
    "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
    "               self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
    "        \n",
    "parameters = Parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x, h_prev, C_prev, p = parameters):\n",
    "    assert x.shape == (vocab_size, 1)\n",
    "    assert h_prev.shape == (H_size, 1)\n",
    "    assert C_prev.shape == (H_size, 1)\n",
    "    \n",
    "    z = np.row_stack((h_prev, x))\n",
    "    f = sigmoid(np.dot(p.W_f.v, z) + p.b_f.v)\n",
    "    i = sigmoid(np.dot(p.W_i.v, z) + p.b_i.v)\n",
    "    C_bar = tanh(np.dot(p.W_C.v, z) + p.b_C.v)\n",
    "\n",
    "    C = f * C_prev + i * C_bar\n",
    "    o = sigmoid(np.dot(p.W_o.v, z) + p.b_o.v)\n",
    "    h = o * tanh(C)\n",
    "\n",
    "    v = np.dot(p.W_v.v, h) + p.b_v.v\n",
    "    y = np.exp(v) / np.sum(np.exp(v))  #softmax\n",
    "\n",
    "    return z, f, i, C_bar, C, o, h, v, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.82471509],\n",
       "       [0.84188191],\n",
       "       [0.37508933],\n",
       "       [0.41195958],\n",
       "       [0.11231604],\n",
       "       [0.44814117],\n",
       "       [0.66069392],\n",
       "       [0.37512382],\n",
       "       [0.45957785],\n",
       "       [0.75864027]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummyVector = np.random.randn(10, 1)\n",
    "sigmoid(dummyVector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(target, dh_next, dC_next, C_prev,\n",
    "             z, f, i, C_bar, C, o, h, v, y,\n",
    "             p = parameters):\n",
    "    \n",
    "    assert z.shape == (vocab_size + H_size, 1)\n",
    "    assert v.shape == (vocab_size, 1)\n",
    "    assert y.shape == (vocab_size, 1)\n",
    "    \n",
    "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
    "        assert param.shape == (H_size, 1)\n",
    "        \n",
    "    dv = np.copy(y)\n",
    "    dv[target] -= 1\n",
    "\n",
    "    p.W_v.d += np.dot(dv, h.T)\n",
    "    p.b_v.d += dv\n",
    "\n",
    "    dh = np.dot(p.W_v.v.T, dv)        \n",
    "    dh += dh_next\n",
    "    do = dh * tanh(C)\n",
    "    do = dsigmoid(o) * do\n",
    "    p.W_o.d += np.dot(do, z.T)\n",
    "    p.b_o.d += do\n",
    "\n",
    "    dC = np.copy(dC_next)\n",
    "    dC += dh * o * dtanh(tanh(C))\n",
    "    dC_bar = dC * i\n",
    "    dC_bar = dtanh(C_bar) * dC_bar\n",
    "    p.W_C.d += np.dot(dC_bar, z.T)\n",
    "    p.b_C.d += dC_bar\n",
    "\n",
    "    di = dC * C_bar\n",
    "    di = dsigmoid(i) * di\n",
    "    p.W_i.d += np.dot(di, z.T)\n",
    "    p.b_i.d += di\n",
    "\n",
    "    df = dC * C_prev\n",
    "    df = dsigmoid(f) * df\n",
    "    p.W_f.d += np.dot(df, z.T)\n",
    "    p.b_f.d += df\n",
    "\n",
    "    dz = (np.dot(p.W_f.v.T, df)\n",
    "         + np.dot(p.W_i.v.T, di)\n",
    "         + np.dot(p.W_C.v.T, dC_bar)\n",
    "         + np.dot(p.W_o.v.T, do))\n",
    "    dh_prev = dz[:H_size, :]\n",
    "    dC_prev = f * dC\n",
    "    \n",
    "    return dh_prev, dC_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear gradients before each backward pass\n",
    "def clear_gradients(params = parameters):\n",
    "    for p in params.all():\n",
    "        p.d.fill(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Clip gradients to mitigate exploding gradients\n",
    "def clip_gradients(params = parameters):\n",
    "    for p in params.all():\n",
    "        np.clip(p.d, -1, 1, out=p.d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_total_loss(self, x, y):\n",
    "    L = 0\n",
    "    \n",
    "    # For each sentence...\n",
    "    for i in np.arange(len(y)):\n",
    "        o, s = self.forward_propagation(x[i])\n",
    "        \n",
    "        # We only care about our prediction of the \"correct\" words\n",
    "        correct_word_predictions = o[np.arange(len(y[i])), y[i]]\n",
    "        \n",
    "        # Add to the loss based on how off we were\n",
    "        L += -1 * sum(np.log(correct_word_predictions))\n",
    "    return L\n",
    " \n",
    "def calculate_loss(self, x, y):\n",
    "    # Divide the total loss by the number of training examples\n",
    "    N = sum((len(y_i) for y_i in y))\n",
    "    return self.calculate_total_loss(x,y)/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def forward_backward(inputs, targets, h_prev, C_prev):\n",
    "    global paramters\n",
    "    \n",
    "    # To store the values for each time step\n",
    "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
    "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
    "    v_s, y_s =  {}, {}\n",
    "    \n",
    "    # Values at t - 1\n",
    "    h_s[-1] = np.copy(h_prev)\n",
    "    C_s[-1] = np.copy(C_prev)\n",
    "    \n",
    "    loss = 0\n",
    "    # Loop through time steps\n",
    "    #assert len(inputs) == T_steps\n",
    "    for t in range(len(inputs)):\n",
    "        x_s[t] = np.zeros((vocab_size, 1))\n",
    "        x_s[t][inputs[t]] = 1 # Input character\n",
    "        \n",
    "        (z_s[t], f_s[t], i_s[t],\n",
    "        C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
    "        v_s[t], y_s[t]) = \\\n",
    "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass\n",
    "        #print(y_s[t].shape)\n",
    "        #print(len(targets[t]))\n",
    "        #print(o_s[t].shape)\n",
    "        #print(targets[t])\n",
    "                 # We only care about our prediction of the \"correct\" words\n",
    "        #correct_word_predictions = y_s[t][len(targets[t]), 0]\n",
    "       \n",
    "        \n",
    "        # Add to the loss based on how off we were\n",
    "        #loss += -1 * sum(math.log(correct_word_predictions))   \n",
    "        loss += -np.log(y_s[t][len(targets[t]), 0]) # Loss for at t\n",
    "        \n",
    "    clear_gradients()\n",
    "\n",
    "    dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
    "    dC_next = np.zeros_like(C_s[0]) #dh from the next character\n",
    "\n",
    "    for t in reversed(range(len(inputs))):\n",
    "        # Backward pass\n",
    "        dh_next, dC_next = \\\n",
    "            backward(target = targets[t], dh_next = dh_next,\n",
    "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
    "                     z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
    "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
    "                     y = y_s[t])\n",
    "\n",
    "    clip_gradients()\n",
    "        \n",
    "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_next_word(h_prev, C_prev, first_char_idx, sentence_length):\n",
    "    x = np.zeros((vocab_size, 1))\n",
    "    x[first_char_idx] = 1\n",
    "\n",
    "    h = h_prev\n",
    "    C = C_prev\n",
    "\n",
    "    indexes = []\n",
    "    \n",
    "    for t in range(sentence_length):\n",
    "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
    "        idx = np.random.choice(range(vocab_size), p=p.ravel())\n",
    "        x = np.zeros((vocab_size, 1))\n",
    "        x[idx] = 1\n",
    "        indexes.append(idx)\n",
    "\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Update the graph and display a sample output\n",
    "def update_status(inputs, h_prev, C_prev):\n",
    "    #initialized later\n",
    "    global plot_iter, plot_loss\n",
    "    global smooth_loss\n",
    "    \n",
    "    # Get predictions for 200 letters with current model\n",
    "\n",
    "    sample_idx = generate_next_word(h_prev, C_prev, inputs[1], len(inputs))\n",
    "    txt = ' '.join(index_to_word[idx] for idx in sample_idx)\n",
    "\n",
    "    # Clear and plot\n",
    "    plt.plot(plot_iter, plot_loss)\n",
    "    display.clear_output(wait=True)\n",
    "    plt.show()\n",
    "\n",
    "    #Print prediction and loss\n",
    "    print(\"----\\n %s \\n----\" % (txt, ))\n",
    "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_paramters(params = parameters):\n",
    "    for p in params.all():\n",
    "        p.m += p.d * p.d # Calculate sum of gradients\n",
    "        #print(learning_rate * dparam)\n",
    "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To delay the keyboard interrupt to prevent the training from stopping in the middle of an iteration\n",
    "import signal\n",
    "\n",
    "class DelayedKeyboardInterrupt(object):\n",
    "    def __enter__(self):\n",
    "        self.signal_received = False\n",
    "        self.old_handler = signal.signal(signal.SIGINT, self.handler)\n",
    "\n",
    "    def handler(self, sig, frame):\n",
    "        self.signal_received = (sig, frame)\n",
    "        print('SIGINT received. Delaying KeyboardInterrupt.')\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        signal.signal(signal.SIGINT, self.old_handler)\n",
    "        if self.signal_received:\n",
    "            self.old_handler(*self.signal_received)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponential average of loss\n",
    "# Initialize to a error of a random model\n",
    "smooth_loss = -np.log(1.0 / vocab_size) * T_steps\n",
    "\n",
    "iteration, pointer = 0, 0\n",
    "\n",
    "# For the graph\n",
    "plot_iter = np.zeros((0))\n",
    "plot_loss = np.zeros((0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.17193191416239"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smooth_loss\n",
    "#smooth_loss2 = -np.log(1.0 / vocab_size) * T_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the graph and display a sample output\n",
    "def print_status(inputs, h_prev, C_prev):\n",
    "    # Get predictions for 200 letters with current model\n",
    "    sample_idx = generate_next_word(h_prev, C_prev, inputs[0], 20)\n",
    "    txt = ' '.join(index_to_word[idx] for idx in sample_idx)\n",
    "    # Clear and plot\n",
    "    #plt.plot(plot_iter, plot_loss)\n",
    "    #display.clear_output(wait=True)\n",
    "    #plt.show()\n",
    "    #Print prediction and loss\n",
    "    print(\"----\\n %s \\n----\" % (txt, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction at breakpoint:  10\n",
      "----\n",
      " post ancient passion advanced mountains impassive ensure descend became eclipse flame allowing surprises excessive fury content rest master retreat do \n",
      "----\n",
      "prediction at breakpoint:  20\n",
      "----\n",
      " owns composed connecticut perfectly trembled afraid duel magic dream astronomer tumult involved played decide craters brain bent instant files so \n",
      "----\n",
      "prediction at breakpoint:  30\n",
      "----\n",
      " universal justice lieu portions ring extend annihilated representations charges shock incidental separated excess mountain extend feared given rapidity burning bits \n",
      "----\n",
      "prediction at breakpoint:  40\n",
      "----\n",
      " confidence dressed believed sent together increases look liability expenses recollect seek locked flowed existing impatiently john entering resign impatience changes \n",
      "----\n",
      "prediction at breakpoint:  50\n",
      "----\n",
      " fatality airship fridriksson practically hall brilliantly destructive mappa startling winds beds govern tight moon explosion uniform growing jumping tear burning \n",
      "----\n",
      "prediction at breakpoint:  60\n",
      "----\n",
      " ought chauffeur seconds speaker clamps release atmospheric mind nest founded swept shrugging shining society notion parties useful uttering startling spots \n",
      "----\n",
      "prediction at breakpoint:  70\n",
      "----\n",
      " window pyramids keep named quantity hidden commander refuge drawn plow centuries left dinner faith supposing gently compass lieu wonders undoubtedly \n",
      "----\n",
      "prediction at breakpoint:  80\n",
      "----\n",
      " published aged instant tongue opening game come bury five involuntary signaled encampment warned turnings engineers over further quit forgetting grown \n",
      "----\n",
      "prediction at breakpoint:  99\n",
      "----\n",
      " does november imagined appearance away heaps sandstone stream barren physical canadian spite infinity idioms supposed special breathed copy furnished towers \n",
      "----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x121703b38>]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAD0CAYAAABdAQdaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd3hUVeL/8fdMZlJJIQnpkIR26CWEGuoKSBUVRf0BtgV1RXdF1F1ZV113XXdt/Kyg2FjFBogKCqhIC70XMYcSepESWugJfP9IdFkXZdAMk5l8Xs/D82TmhpnPJeGTk3PPvddx9uxZRESkfHP6OoCIiFyYylpExA+orEVE/IDKWkTED6isRUT8gMsbL2qMCQGaA7uAYm+8h4hIAAoCkoHF1tqT527wSllTUtRzvPTaIiKBrh2Qe+4T3irrXQBjx44lKSnJS28hIhJYdu/eTf/+/aG0Q8/lrbIuBkhKSiItLc1LbyEiErD+Z/pYBxhFRPyAylpExA+orEVE/IDKWkTED6isRUT8wAVXgxhj3MAYIIOSI5SDgTBgMrC+9NNGWms/8FJGEZEKz5Olez0Al7W2jTGmC/A4MAV41lr7TFkH+nDJNsYv2c77t7XC6XSU9cuLiPglT6ZB1gEuY4wTiAJOA82AnsaY2caY140xkWUVKDjIyaLNBSzZcqCsXlJExO95UtaFlEyB5AGjgeeBRcD91tr2QD7wSFkF6lo/kfDgID5atr2sXlJExO95UtZDgWnW2tpAY0rmr6dYa5eWbp8INC2rQOHBLro1SOKz1bs4cVrXgBIRAc/K+gBwqPTjAsANTDLGtCh97jJg6fn+4i/VNyuNIyeK+Orb78ryZUVE/JYnBxhHAG8YY+YAwcBwSqZEXjDGnAZ2A7eVZahW1eNIigpl4rId9GqUUpYvLSLily5Y1tbaQqDfeTbllH2cEkFOB32apvDanE3sKzxJfKUQb72ViIhfKLcnxVzdNI3iM2eZtHKnr6OIiPhcuS1rkxRJ/ZQoPlq2w9dRRER8rtyWNcDVWWms3nGIvN2HfR1FRMSnynVZX9kkBXeQg3FLtOZaRCq2cl3WcZVC6Fw3kYnLd3Cq6Iyv44iI+Ey5LmuAftlVKTh6iq/ztOZaRCqucl/W7WrFkxgVwoeaChGRCqzcl7UryEnfrDRm2j18d/iEr+OIiPhEuS9rgGuzq3LmLFrGJyIVll+UdWZ8BC0yYhm3ZBtnz571dRwRkUvOL8oaoH+rauTvO8qnOqNRRCogvynr3o1SaJAaxT+n5HH8lC6dKiIVi9+UtdPp4OFe9dl16ASvzs73dRwRkUvKb8oaoEVmLD0bJjNq1kZ2HTru6zgiIpeMX5U1wJ+616H47FmenGp9HUVE5JLxu7KuGhvO4HaZTFy+g/kb9/s6jojIJeF3ZQ1wV6daZMSF88CElRw9WeTrOCIiXueXZR0WHMRT1zZm+4Hj/HNKnq/jiIh43QVv62WMcVNyR/MMoBgYbK3NK932/4C7rbWtvRnyfJpnxHJrTiav526ie4Mk2tSMv9QRREQuGU9G1j0Al7W2DfAY8DiAMaYp8FvA4b14P+++robM+AjuH79K0yEiEtA8Ket1gMsY4wSigNPGmDjgH8A93gx3IWHBQTx+VQN2HDzO5FU6s1FEApcnZV1IyRRIHjAaeAF4HbgXOOK1ZB5qXT2O6vERTNBFnkQkgHlS1kOBadba2kBjIBdoCIwE3gfqGWP+v/ci/jyHw8HVWaks2lTAtoJjvoohIuJVnpT1AeBQ6ccFwBagkbW2I3A9sNZa69PpkD5NUgH4eLlG1yISmDwp6xFAljFmDvA1MNxae9S7sS5O1dhwWmbGMnH5Dl1CVUQC0gWX7llrC4F+P7FtM9CqjDP9In2z0nhgwipWbDtI02qVfR1HRKRM+eVJMefTvWESIS4nEzUVIiIBKGDKOjLUTdf6SXy6cienis74Oo6ISJkKmLIGuDorlYPHTjP1m92+jiIiUqYCqqzb16pC9SoRjJy5UQcaRSSgBFRZBzkd3NmxJt/uOswMu8fXcUREykxAlTVAnyYppMaE8eLXGzS6FpGAEXBl7Q5yckeH6izbepAF+QW+jiMiUiYCrqwBrs2uSnylEF6eucHXUUREykRAlnWoO4hB7TKZs34f8zbu83UcEZFfLSDLGmBAq3Qy4yO4/d9LWbX9oK/jiIj8KgFb1pVCXIwd1JLocDcDX1/E2p2HfR1JROQXC9iyBkiJCeO9wa0IDw5iwOsLydutwhYR/xTQZQ0lV+R7d3Ar3EEOrh05n3kbNIctIv4n4MsaIDM+go/uzCE5JpSb3lzER8u2+zqSiMhFqRBlDZAaE8a4O9qQnR7LvR+uZMJSFbaI+I8KU9YA0WFuxtzaguz0yjwxJU93RBcRv1Ghyhog2OVkeM+67Cs8yRu5m3wdR0TEIxWurAGyqlWma71EXpmdT8HRU76OIyJyQRWyrAHuv9xw7FQRL83QKekiUv5d8B6Mxhg3MAbIAIqBwZSU/KuAA1gPDLLW+tUEcK3ESPpmpfH2/C3ckpNBWuVwX0cSEflJnoysewAua20b4DHgceAflNzlPKf0c3p7KZ9XDe1SGxzw1DTr6ygiIj/Lk7JeB7iMMU4gCjgN9LXWzjbGBANJwCEvZvSalJgwbmtXnU9W7GRh/n5fxxER+UmelHUhJVMgecBo4HlrbbExJh34BogHVnotoZcN6VST1JgwHv7kG04X60a7IlI+eVLWQ4Fp1traQGNgjDEm1Fq7xVpbCxgFPOvNkN4UFhzEw73rYb87wr/nb/F1HBGR8/KkrA/wn2mOAsANTDLG1Cp97gjg10PSrvUS6VC7CiO+XMeewyd8HUdE5H94UtYjgCxjzBzga2A48AjwljFmBnBj6XN+y+Fw8OgV9TlVdIa73luutdciUu5ccOmetbYQ6HeeTTnnec5vZcZH8OQ1jXhgwip6v5DLqAHNaJgW7etYIiJABT4p5nyubJrK+DtaA9B31DzeXbhVd0gXkXJBZf0jjdJimHR3W1pmxjJ84mpufGMR2w8c83UsEangVNbnERsRzJhbWvC3KxuwbMsBLh8xW5dUFRGfUln/BKfTwcBW6Uwb2p4GqdE8MGEVS7cc8HUsEamgVNYXkFY5nNE3ZZMcHcof3l/O4ROnfR1JRCoglbUHokLdPH9DU3YdOsHwj1broKOIXHIqaw9lVavMvV1qM3nVLsZp/lpELjGV9UW4o0MNWleP49FPv2FbgVaIiMilo7K+CEFOB0/3a4zT4eCB8as4c0bTISJyaaisL1JqTBh/6VWX+fn7eWehLvwkIpeGyvoX6JddlQ61q/DE53ls2X/U13FEpAJQWf8CDoeDf/ZtiCvIwT0frODQcS3nExHvUln/QsnRYfyrbyPW7DhEnxdzsbuP+DqSiAQwlfWv0KNhMu8NbsXRU8Vc9fJcJq/a6etIIhKgVNa/UnZGLJPvbkudpEjuenc5Q95dxp4juoGBiJQtlXUZSIwK5f3bWjOsS22+/OY7Oj8ziw8Xb/N1LBEJICrrMhLscnL3ZbWYck876iZH8cCEVbw8c4OvY4lIgFBZl7EaVSrx3uBW9GmSwpNTLe8s0FpsEfn1LnhbL2OMGxgDZADFwGAgFHih9PFJ4EZr7Xfei+lfnE4HT1/bmMITRfzlkzVEhrro0yTV17FExI95MrLuAbistW2Ax4DHgeeAu621HYGPgD96LaGfcgc5eal/Fi0yYhn24Upy1+/zdSQR8WOelPU6wGWMcQJRwGngemvtitLtLkDLH84j1B3EazdlU6NKJe4cu5SNewt9HUlE/JQnZV1IyRRIHjAaeN5auwvAGNMGuAsY4a2A/i4y1M1rN2XjDnIyaMwSDh475etIIuKHPCnrocA0a21toDEwxhgTaoy5DhgF9LTW7vVmSH9XNTacVwY2Y8eB4/zunWWcKjrj60gi4mc8KesDwKHSjwsAN3AdJSPqjtbafC9lCyjZGbH865qGzM/fz61vLeaIbg8mIhfBk7IeAWQZY+YAXwN/Ln0uEvjIGDPTGPNXL2YMGFc1TeOpaxoxP38/17+6gL1HTvo6koj4iQsu3bPWFgL9fvT0WO/ECXzXZlclvlIId45dRt+R8xh9YzYmKdLXsUSknNNJMT7QqU4C7w5uybFTxfR+MZc3cjfprjMi8rNU1j7StFplpt7TjnY143ls8lpuenORLgAlIj9JZe1D8ZVCeO2mbB6/qgGLNxfQ+4Vclm454OtYIlIOqax9zOFw0L9lOhPvzCHEFcT1r87n3YVbfR1LRMoZlXU5UTc5ik/vyqF1jXiGT1zNY5PWcvas5rFFpITKuhyJCQ/mzZubc0tOBm/M3cSfJqymWAceRQQPlu7JpRXkdPBwr3pEhrh4/usNHD1VxIjrmuAO0s9VkYpMZV0OORwO7u1qiAhx8cSUPApPFvFy/yzCg/XlEqmoNFwrx27vUIMnrm7I7HV7uWH0QgqO6iJQIhWVyrqcu6FFNUYNaEbersNcM3Ie2wqO+TqSiPiAytoPdK2fxNhBLdl/9BS9X8xlpt3j60gicomprP1EdkYsnwzJISkqlFveWsyIL9dppYhIBaKy9iMZ8RFMvDOHq5qm8tz09dz0xiL2HNYp6iIVgcraz4QFB/HMtY154uqGLNlSQLfn5jD9W92rWCTQqaz9kMPh4IYW1Zh8d1sSo0L57ZglPPLJGk6cLvZ1NBHxEpW1H6uZEMnHQ9pwa04mY+Zv4eqX55Gvm/KKBCSVtZ8LcQXxcO96vHZjNjsPHaf3C7l8smKHr2OJSBlTWQeIzvUS+fz37aiXEsUf3l/BQx+v5mSRpkVEAsUFz182xriBMUAGUAwMttbmlW4bAVhr7ShvhhTPpMSE8e7gVjw1zfLq7HxWbz/ES/2zSKsc7utoIvIreTKy7gG4rLVtgMeAx40xVYwxU4ArvJpOLpo7yMnwHnUZNSCLjXuP0uuFXGboJBoRv+dJWa8DXMYYJxAFnAYqAY8Cb3svmvwa3RokM+nutiUn0by5mKem5VFUfMbXsUTkF/KkrAspmQLJA0YDz1trN1lrF3ozmPx6mfERfDwkh+ubV+WlGRvp/9pCdh067utYIvILeFLWQ4Fp1traQGNgjDEm1LuxpKyEuoP4Z99GPNuvMat3HKL7c3OYuma3r2OJyEXypKwPAIdKPy4A3ECQ1xKJV1ydlcZnv29Htdhw7nhnKQ9+tJqjJ4t8HUtEPORJWY8Asowxc4CvgeHW2qPejSXekBkfwfg72nB7h+q8v3grPZ6fw5LNBb6OJSIeuODSPWttIdDvJ7Y9WtaBxLuCXU4e7F6X35gEho1bybWvzOe29tUZ2rk2oW79wiRSXumkmAqqZfU4pt7Tnuuyq/LKrHx6v5DLym0HfR1LRH6CyroCqxTi4p99G/HmLc05cqKIq16ey7+m5unMR5FySGUtdDIJTBvanr5ZaYycuZGez+eyfOsBX8cSkXOorAWA6DA3T13bmDdvac7Rk0X0HTmPf3z+rS67KlJOqKzlv3w/yr6ueVVenZ1Pj+e0YkSkPFBZy/+ICnXzxNWNGDuoJaeKz3DtK/N59NNvOHZK67JFfEVlLT8pp2Y80+5pz02tM3hr3ma6jphN7vp9vo4lUiGprOVnRYS4ePSK+oy7ozXBLicDXl/I/eNWcvDYKV9HE6lQVNbikeYZsXz++3YM6VSDj5bvoPOzs5i0cidnz571dTSRCkFlLR4LdQdx/+V1+PSuHFJiwrj7veX8dswSth845utoIgFPZS0XrX5KNBPvzOEvveqxIH8/XZ6dzejZ+bpetogXqazlFwlyOvht20y+GNqeNjXiePzzb7nixbk6mUbES1TW8qukVQ7ntZuyGTUgi4Kjp7h65DyGT1ytA5AiZUxlLb+aw+GgW4NkvhrWgd/mZPLB4m385plZjFuyjTNndABSpCyorKXMVApx8VCveky6qy2Z8RHcP34V14yax5odhy78l0XkZ6mspczVS4li3O2teeqaRmzZf4wrXszl4U/WaGpE5FdQWYtXOJ0Ors2uytfDOjKwVTrvLNhCp6dn8t6irRRrakTkoqmsxauiw938tU8DJt/djloJkTz40WqufGkuS7fo4lAiF0NlLZdEvZQoPri9Fc9d34S9R07Sd+R8hn6wgu8On/B1NBG/cMF7MBpj3MAYIAMoBgYDRcBbwFlgDTDEWqszIuRnORwO+jRJpXPdRF6euYHRszcx7ZvdDOlUk9+2zdQ9IEV+hicj6x6Ay1rbBngMeBx4FnjIWtsOcAB9vBdRAk1EiIv7L6/Dl/e2p12teJ6aZun87CymrN6la42I/ARPynod4DLGOIEo4DTQDJhVun0K0Nk78SSQpcdF8MrAbN4d1JJKIS5+N3YZ1726QEv9RM7Dk7IupGQKJA8YDTwPOKy13w+BjgDRXkknFUKbmvFMvrstj1/VgA17Cun9Yi4PjF/JHs1ni/zAk7IeCkyz1tYGGlMyfx18zvZI4KAXskkF4gpy0r9lOjPu68igtplMXL6Djk/P5Pnp6zl+SveBFPGkrA8A3/9eWgC4geXGmI6lz3UH5pR9NKmIosPc/LlnPb66twMdTRWe/XIdnZ6eyfil27U+Wyo0T8p6BJBljJkDfA0MB4YAfzXGzKdklD3eexGlIkqPi+Dl/s0Yd0drEqNCuG/cSnq9kKvbikmFdcGle9baQqDfeTZ1KPs4Iv+teUYsE+/MYfLqXTw5NY8Bry+kfe0q/KlbHeqlRPk6nsglo5NipNxzOh1c0TiF6cM68FDPuqzcdpCeL8zh3g9W6C41UmGorMVvhLiCGNSuOrPv78Rt7aszefUufvP0LP42eS0FR3WRKAlsKmvxO9Hhbh7sXpeZ93XkyqYpvDl3E+2fnMFzX62n8GSRr+OJeIXKWvxWSkwYT17TmGn3tCenZhwjvlpHhydn8HruJk6c1nI/CSwqa/F7tRIjeWVgNh8PyaFOciR/m7yWjk/NZOzCLZwq0iVrJDCorCVgNKkaw9hBrRg7qCUpMaH8eeIaLnt2JuOWbNOd18Xvqawl4OTUjGfC79rw5s3NiQ5zc//4VXR+dhYTlm5XaYvfUllLQHI4HHSqk8Cku9ry6sBmhAW7GDZuJV1GzGa8Slv8kMpaAprD4aBr/SQ+u7stowZkEeoO4r5xK/nNM7P4cPE2zWmL31BZS4XgdDro1iCZz3/fltE3ZhMd5uaBCavo+NQMxszbrNUjUu6prKVCcTgcdKmXyKd35fDWLc1JjgnjkU+/oe2/ZvDyzA0cPnHa1xFFzuuC1wYRCUQOh4OOJoEOtauwIL+Al2du4MmplpEzNzKwVTo352SQEBnq65giP1BZS4XmcDhoXSOO1jXiWL39ECNnbWDkrI28lruJvllpDG6XSfUqlXwdU0RlLfK9hmnRvNy/GZv2HWX0nHzGL93O+4u30qVuIre1r06z9Mo4HA5fx5QKSmUt8iOZ8RH846qG3NO5Fm/P38LbC7bwxdrvaFI1hkHtMulWPwlXkA73yKWlshb5CQmRoQzravhdxxpMWLqd13M3cde7y0mNCeOmNulc17wa0WFuX8eUCkLDA5ELCA92MbB1BtOHdWT0jdmkVQ7jH5/n0fqJ6fzl4zVs3Fvo64hSAWhkLeKhIGfJsr8u9RJZs+MQb87dzAeLt/H2gi20r12Fm9uk07F2Ak6n5rWl7F2wrI0xNwM3lz4MBZoANwIPAkeBqdbav3spn0i51CA1mmf6NeZP3evw3qKtvLNgC7e+tYT0uHAGtkrn2mZViQ7XFImUHcfZs57fMdoY8xKwEngI6GitzTfGvAOMstbmnvN5GcCm6dOnk5aWVsaRRcqf08VnmLpmN2PmbWbJlgOEup30aZzKwNbpNEiN9nU88RPbt2/nsssuA8i01m4+d5vH0yDGmGygPvBXYIi1Nr9001ygLZD7U39XJNC5g5z0bpxC78YpfLPzEO8s2MLE5Tv4YMk2mlSNYUCrdHo1SibUHeTrqOKnLuYA43BKinovEG6MqWOMCQJ6ABHeCCfij+qnRPPE1Y1YOLwzD/eqx+ETp7lv3Epa/mM6f5u8Vgck5RfxaGRtjIkBjLV2RunjgcBI4CSwBtjntYQifio6zM2tbTO5JSeD+Rv3M3bRVsbM28zruZtoVT2WG1pU4/L6SRpti0c8nQZpD0w/5/HlpX9OAx8Bb5ZxLpGA4XA4aFMznjY149l75CTjlm7j/UXb+MP7K6gc7uaqpmlc36IqtRMjfR1VyjFPy9oA+ec83gksAo4DY62135R1MJFAVCUyhDs71uSO9jWYt3E/7y3aytsLNvPG3E1kVYvhuuZV6dUohYgQraqV/3ZRq0E8pdUgIp7bX3iSj5bt4P3FW9m49yjhwUH0apRMv+yquh5JBVMmq0FExDviKoUwuH11BrXLZNnWA3yweBuTV+3iwyXbqR4fwTXZafTNSiMxSpdsrchU1iLlhMPhoFl6LM3SY3mkd30+W72L8Uu28+RUy9PTLO1qVaFvszS61kvUQckKSGUtUg5FhLjol12VftlV2bzvKBOWbWfC0u38/r3lRIa66NUomb5ZaZomqUBU1iLlXEZ8BMO6GoZ2rs38/P1MWLadT1bs5L1F26gWG86VTVO5umkqGfE63SGQqaxF/ITT6SCnZjw5NeP5W58ipq7ZzcTlO3jh6/U8P309TavFcGWTVHo1SiauUoiv40oZU1mL+KGIEBd9m6XRt1kauw+d4JMVO5i4fAePfPoNj01eS/ta8VzZNJXOdRO1DDBA6Kso4ueSokO5vUMNbu9Qg7zdh5m4fAeTVuzkD++vIMwdRJd6iVzROIX2tasQ7NIl7P2VylokgNRJiuLB7lH88fI6LNlygI9X7ODz1bv4dOVOokJddG+QzBVNUmiZGatbk/kZlbVIAHI6HbTIjKVFZiyP9q7P3A37+HTlTiav2skHS7YRXymY7g2S6dUomeYZsbphgh9QWYsEuGCXk051EuhUJ4ETp4uZkbeHSat28uGSkrvcJEaF0KNhMj0bJpNVrbKKu5xSWYtUIKHuILo3TKZ7w2SOnixiet4eJq/cydiFW3lz7maSokLp1iCJno2SaabiLldU1iIVVESIiysap3BF4xSOnDjN13l7+GzVLt5dtJW35m0mITKEy+sn0b1BEi00x+1zKmsRITLUTZ8mqfRpkkrhySK+ztvDlNW7GLe0ZKokNiKYLnUT6dYgiTY14whx6XT3S01lLSL/pdI5I+5jp4qYvW4vU9bs5rPVu/hgyTYqhbjoVCeBy+sn0tEkUEnruC8J/SuLyE8KD3bRrUEy3Rokc7KomHkb9zNtzW6+XPsdk1buJDjISU7NOLrWT+KyugkkROrKgN6ishYRj4S4guhkEuhkEnj8qrMs3XKAL77ZzbS1u5nx0WocDmhSNYYu9RLpWi+RGlUq6SJTZUhlLSIXLeicddx/7lmXvN1H+HLtd3y59juenGp5cqolIy6cznUTuaxuItkZlXHrAOWvorIWkV/F4XBQNzmKuslR/P6yWuw6dJyvvt3Dl2u/49/zt/Ba7iaiQl10NAlcVjeBDrWrEBMe7OvYfueCZW2MuRm4ufRhKNAEGAD8CSgCvrLWPuSlfCLiZ5KjwxjYKp2BrdIpPFlE7vq9fPXtHmbk7eHTlTsJcjpoVq0yneok8Js6CdRO1HSJJy7qHozGmJeAlcDvgP7At8Ac4HfW2tXnfF4GugejiJzjzJmzrNx+kOnf7uHrvD2s3XUYgNSYMDqaKnQyCbSpGUd4cMX9hb9M7sFojMkG6ltrhxhjWgGxgJuS0XZx2cUVkUDkdDpoWq0yTatV5r7LDbsPnWCGLSnuict3MHbhVoKDnLSsHkuH2lXoaBKoUSVCo+5SF/MjbDjw19KPVwOTgf3AKiCvjHOJSIBLig7lhhbVuKFFNU4WFbNk8wFm5O1h5rq9/P2zb/n7Z9+SVjmMDrWr0L52FdrUiCMy1O3r2D7jUVkbY2IAY62dUfrxg5SMsncYY54EhgFPeTGniASwEFfQD3fBeQjYVnCMWev2MmvdXj4uHXW7nA6yqlWmfe142teuQoOU6Ap17RJPR9btgemlHx8HCkv/AOwCqpRxLhGpwKrGhjOgVToDWqVzqugMS7ccYPb6vcxet5env1jH01+so3K4m5ya8bSrFU/bWlVIjQnzdWyv8rSsDZAPYK09aYwZBnxhjDkBHOQ/q0VERMpUsMtJ6xpxtK4Rxx+71WFf4UnmbtjH7HX7mL1+L5NX7QKgenwEbWuVjM5b14gjKsCmTC5qNYintBpERC6Fs2fPsu67Quas30vuhn0s2lTAsVPFBDkdNEyNJqdmHDk14slKr0you/xffKpMVoOIiJQ3DocDkxSJSYpkULvqnCo6w/KtB8jdsI+5G/YxalY+L83YSLDLSXZ65R9G3Y1So/3ukq8qaxEJGMEuJy2rx9GyehzDuhqOnDjNok0FzN2wn3kb9/HUNAtARHAQLTJjS6ZXqsdTLyWKoHJ+sFJlLSIBKzLUzWWl1ycB2F94kgX5BczP38e8jfuZYfeWfp6LlpmxtKoeR8vMuHJZ3iprEakw4iqF0LNRMj0bJQOw5/AJ5ufvZ0H+fhbkF/DVt3sAiAxxkZ1RuWSUnhlLg9Ron1+ISmUtIhVWQlToD3fIAfju8Ikfinvhpv+MvMPcQTRLr0yLzFiaZ8TStFrMJT9gqbIWESmV+KPy3nPkBIs2FbB4UwELNxUw4qt1nD0L7iAHjdJiyM6oTIuMWJqlV/b6lQRV1iIiPyEhMpRejVLo1SgFgEPHTrNkSwGLNhewaFMBb+Ru4pVZ+QDUTqxEdkYsOTXi6dEwqcyvaaKyFhHxUHT4fx+wPHG6mJXbDrJ4cwFLthxg0oqdvLtwK9OHdaBGlUpl+t4qaxGRXyjUHfTDUkGA4jNnOXT8NLERZT8l4l+rwkVEyrEgp8MrRQ0qaxERv6CyFhHxAyprERE/oLIWEfEDKmsRET+gshYR8QPeWmcdBLB7924vvbyISOA5pzP/58Ij3irrZID+/ft76eVFRAJaMrDx3Ce8VdaLgXaU3Ey32EvvISISaIIoKerFP97glbJ35nMAAAMaSURBVHswiohI2dIBRhERP1CuLuRkjHECLwONgZPAIGvtBt+mKnvGGDfwBpABhAB/B9YCbwFngTXAEGvtGR9F9CpjTAKwFOgCFBHg+22MeRC4Agim5Pt7FoG/z25gDCXf48XAYAL4a22MaQn8y1rb0RhTk/PspzHmEaAnJf8O91hrF13Me5S3kfWVQKi1tjXwJ+AZH+fxlgHAfmttO6Ab8CLwLPBQ6XMOoI8P83lN6X/iV4DjpU8F9H4bYzoCbYAcoANQlQDf51I9AJe1tg3wGPA4AbrfxpgHgNeA0NKn/mc/jTFZlHz9WwLXAy9d7PuUt7JuC0wFsNYuALJ9G8drxgF/Kf3YQclP2maUjLgApgCdfZDrUngaGAXsLH0c6Pt9ObAamAhMAiYT+PsMsA5wlf62HAWcJnD3eyNw9TmPz7efbYEvrLVnrbVbKfm3qXIxb1LeyjoKOHTO42JjTLmaqikL1tpCa+0RY0wkMB54CHBYa78/2nsEiPZZQC8xxtwM7LXWTjvn6UDf73hKBh3XAncAYwFngO8zQCElUyB5wGjgeQL0a22tnUDJD6PvnW8/f9xtF73/5a2sDwOR5zx2WmuLfBXGm4wxVYEZwNvW2neBc+fuIoGDPgnmXbcCXYwxM4EmwL+BhHO2B+J+7wemWWtPWWstcIL//k8aiPsMMJSS/a5NyTGoMZTM2X8vUPcbzv9/+cfddtH7X97Kei4lc10YY1pR8utjwDHGJAJfAH+01r5R+vTy0vlNgO7AHF9k8yZrbXtrbQdrbUdgBXAjMCXA9zsX6GaMcRhjUoAIYHqA7zPAAf4zkiwA3FSA7/FS59vPucDlxhinMaYaJQPRfRfzouVtimEiJSOveZTM5d7i4zzeMhyoDPzFGPP93PUfgOeNMcHAt5RMj1QEw4DRgbrf1trJxpj2wCJKBkdDgE0E8D6XGgG8YYyZQ8mIejiwhMDfbzjP97S1trj032I+//k+uCg6KUZExA+Ut2kQERE5D5W1iIgfUFmLiPgBlbWIiB9QWYuI+AGVtYiIH1BZi4j4AZW1iIgf+D85CJXIYVDRJQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = Parameters()\n",
    "list_of_breakpoints = [10,20,30,40,50,60,70,80,99]\n",
    "iteration=0\n",
    "plot_loss_inner = []\n",
    "for i in range(100):\n",
    "    if pointer + T_steps >= len(train_data) or iteration == 0:\n",
    "        g_h_prev = np.zeros((H_size, 1))\n",
    "        g_C_prev = np.zeros((H_size, 1))\n",
    "        pointer = 0\n",
    "    inputs = XTrain[:T_steps]\n",
    "    targets = yTrain[:T_steps]\n",
    "\n",
    "    \n",
    "    loss, g_h_prev, g_C_prev = \\\n",
    "        forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
    "    smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "    if iteration in list_of_breakpoints:\n",
    "        print('prediction at breakpoint: ', iteration)\n",
    "        print_status(inputs, g_h_prev, g_C_prev)\n",
    "\n",
    "    update_paramters()\n",
    "    plot_loss_inner = np.append(plot_loss_inner, [loss])\n",
    "\n",
    "    pointer += T_steps\n",
    "    iteration += 1\n",
    "\n",
    "plt.plot(plot_loss_inner)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate numerical gradient\n",
    "def calc_numerical_gradient(param, idx, delta, inputs, target, h_prev, C_prev):\n",
    "    old_val = param.v.flat[idx]\n",
    "    \n",
    "    # evaluate loss at [x + delta] and [x - delta]\n",
    "    param.v.flat[idx] = old_val + delta\n",
    "    loss_plus_delta, _, _ = forward_backward(inputs, targets,\n",
    "                                             h_prev, C_prev)\n",
    "    param.v.flat[idx] = old_val - delta\n",
    "    loss_mins_delta, _, _ = forward_backward(inputs, targets, \n",
    "                                             h_prev, C_prev)\n",
    "    \n",
    "    param.v.flat[idx] = old_val #reset\n",
    "\n",
    "    grad_numerical = (loss_plus_delta - loss_mins_delta) / (2 * delta)\n",
    "    # Clip numerical error because analytical gradient is clipped\n",
    "    [grad_numerical] = np.clip([grad_numerical], -1, 1) \n",
    "    \n",
    "    return grad_numerical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import uniform\n",
    "# Check gradient of each paramter matrix/vector at `num_checks` individual values\n",
    "def gradient_check(num_checks, delta, inputs, target, h_prev, C_prev):\n",
    "    global parameters\n",
    "    \n",
    "    # To calculate computed gradients\n",
    "    _, _, _ =  forward_backward(inputs, targets, h_prev, C_prev)\n",
    "    \n",
    "    \n",
    "    for param in parameters.all():\n",
    "        #Make a copy because this will get modified\n",
    "        d_copy = np.copy(param.d)\n",
    "\n",
    "        # Test num_checks times\n",
    "        for i in range(num_checks):\n",
    "            # Pick a random index\n",
    "            rnd_idx = int(uniform(0, param.v.size))\n",
    "            \n",
    "            grad_numerical = calc_numerical_gradient(param,\n",
    "                                                     rnd_idx,\n",
    "                                                     delta,\n",
    "                                                     inputs,\n",
    "                                                     target,\n",
    "                                                     h_prev, C_prev)\n",
    "            grad_analytical = d_copy.flat[rnd_idx]\n",
    "\n",
    "            err_sum = abs(grad_numerical + grad_analytical) + 1e-09\n",
    "            rel_error = abs(grad_analytical - grad_numerical) / err_sum\n",
    "            # If relative error is greater than 1e-06\n",
    "            if rel_error > .05:\n",
    "                print('%s (%e, %e) => %e'\n",
    "                      % (param.name, grad_numerical, grad_analytical, rel_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = Parameters()\n",
    "iteration = 0\n",
    "\n",
    "gradient_check(10, .005, [1,2,3,4], [2,3,4,5], g_h_prev, g_C_prev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of hidden units: Try doubling and halving your number of hidden units. And after training, plot the training loss vs the number of training epochs, and show the text sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants and hyper-params\n",
    "H_size = 20 # Size of the hidden layer\n",
    "T_steps = 10\n",
    "# Number of time steps (length of the sequence) used for training\n",
    "learning_rate = .005# Learning rate\n",
    "weight_sd = 0.1 # Standard deviation of weights for initialization\n",
    "z_size = H_size + vocab_size # Size of concatenate(H, X) vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "# We use random weights with normal distribution (0, weight_sd) for  tanh  activation function \n",
    "# and (0.5, weight_sd) for  sigmoid  activation function.\n",
    "# Biases are initialized to zeros.\n",
    "class Param:\n",
    "    def __init__(self, name, value):\n",
    "        self.name = name\n",
    "        self.v = value #parameter value\n",
    "        self.d = np.zeros_like(value) #derivative\n",
    "        self.m = np.zeros_like(value) #momentum for AdaGrad\n",
    "        \n",
    "class Parameters:\n",
    "    def __init__(self):\n",
    "        self.W_f = Param('W_f', \n",
    "                         np.random.randn(H_size, z_size) * weight_sd + 0.5)\n",
    "        self.b_f = Param('b_f',\n",
    "                         np.zeros((H_size, 1)))\n",
    "\n",
    "        self.W_i = Param('W_i',\n",
    "                         np.random.randn(H_size, z_size) * weight_sd + 0.5)\n",
    "        self.b_i = Param('b_i',\n",
    "                         np.zeros((H_size, 1)))\n",
    "\n",
    "        self.W_C = Param('W_C',\n",
    "                         np.random.randn(H_size, z_size) * weight_sd)\n",
    "        self.b_C = Param('b_C',\n",
    "                         np.zeros((H_size, 1)))\n",
    "\n",
    "        self.W_o = Param('W_o',\n",
    "                         np.random.randn(H_size, z_size) * weight_sd + 0.5)\n",
    "        self.b_o = Param('b_o',\n",
    "                         np.zeros((H_size, 1)))\n",
    "\n",
    "        #For final layer to predict the next character\n",
    "        self.W_v = Param('W_v',\n",
    "                         np.random.randn(vocab_size, H_size) * weight_sd)\n",
    "        self.b_v = Param('b_v',\n",
    "                         np.zeros((vocab_size, 1)))\n",
    "        \n",
    "    def all(self):\n",
    "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
    "               self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
    "        \n",
    "parameters_double = Parameters()\n",
    "\n",
    "def forward(x, h_prev, C_prev, p = parameters_double):\n",
    "    assert x.shape == (vocab_size, 1)\n",
    "    assert h_prev.shape == (H_size, 1)\n",
    "    assert C_prev.shape == (H_size, 1)\n",
    "    \n",
    "    z = np.row_stack((h_prev, x))\n",
    "    f = sigmoid(np.dot(p.W_f.v, z) + p.b_f.v)\n",
    "    i = sigmoid(np.dot(p.W_i.v, z) + p.b_i.v)\n",
    "    C_bar = tanh(np.dot(p.W_C.v, z) + p.b_C.v)\n",
    "\n",
    "    C = f * C_prev + i * C_bar\n",
    "    o = sigmoid(np.dot(p.W_o.v, z) + p.b_o.v)\n",
    "    h = o * tanh(C)\n",
    "\n",
    "    v = np.dot(p.W_v.v, h) + p.b_v.v\n",
    "    y = np.exp(v) / np.sum(np.exp(v)) #softmax\n",
    "\n",
    "    return z, f, i, C_bar, C, o, h, v, y\n",
    "\n",
    "def backward(target, dh_next, dC_next, C_prev,\n",
    "             z, f, i, C_bar, C, o, h, v, y,\n",
    "             p = parameters_double):\n",
    "    \n",
    "    assert z.shape == (vocab_size + H_size, 1)\n",
    "    assert v.shape == (vocab_size, 1)\n",
    "    assert y.shape == (vocab_size, 1)\n",
    "    \n",
    "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
    "        assert param.shape == (H_size, 1)\n",
    "        \n",
    "    dv = np.copy(y)\n",
    "    dv[target] -= 1\n",
    "\n",
    "    p.W_v.d += np.dot(dv, h.T)\n",
    "    p.b_v.d += dv\n",
    "\n",
    "    dh = np.dot(p.W_v.v.T, dv)        \n",
    "    dh += dh_next\n",
    "    do = dh * tanh(C)\n",
    "    do = dsigmoid(o) * do\n",
    "    p.W_o.d += np.dot(do, z.T)\n",
    "    p.b_o.d += do\n",
    "\n",
    "    dC = np.copy(dC_next)\n",
    "    dC += dh * o * dtanh(tanh(C))\n",
    "    dC_bar = dC * i\n",
    "    dC_bar = dtanh(C_bar) * dC_bar\n",
    "    p.W_C.d += np.dot(dC_bar, z.T)\n",
    "    p.b_C.d += dC_bar\n",
    "\n",
    "    di = dC * C_bar\n",
    "    di = dsigmoid(i) * di\n",
    "    p.W_i.d += np.dot(di, z.T)\n",
    "    p.b_i.d += di\n",
    "\n",
    "    df = dC * C_prev\n",
    "    df = dsigmoid(f) * df\n",
    "    p.W_f.d += np.dot(df, z.T)\n",
    "    p.b_f.d += df\n",
    "\n",
    "    dz = (np.dot(p.W_f.v.T, df)\n",
    "         + np.dot(p.W_i.v.T, di)\n",
    "         + np.dot(p.W_C.v.T, dC_bar)\n",
    "         + np.dot(p.W_o.v.T, do))\n",
    "    dh_prev = dz[:H_size, :]\n",
    "    dC_prev = f * dC\n",
    "    \n",
    "    return dh_prev, dC_prev\n",
    "\n",
    "# Clear gradients before each backward pass\n",
    "def clear_gradients(params = parameters_double):\n",
    "    for p in params.all():\n",
    "        p.d.fill(0)\n",
    "        \n",
    "        \n",
    "# Clip gradients to mitigate exploding gradients\n",
    "def clip_gradients(params = parameters_double):\n",
    "    for p in params.all():\n",
    "        np.clip(p.d, -1, 1, out=p.d)\n",
    "        \n",
    "def forward_backward(inputs, targets, h_prev, C_prev):\n",
    "    global paramters\n",
    "    \n",
    "    # To store the values for each time step\n",
    "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
    "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
    "    v_s, y_s =  {}, {}\n",
    "    \n",
    "    # Values at t - 1\n",
    "    h_s[-1] = np.copy(h_prev)\n",
    "    C_s[-1] = np.copy(C_prev)\n",
    "    \n",
    "    loss = 0\n",
    "    # Loop through time steps\n",
    "    for t in range(len(inputs)):\n",
    "        x_s[t] = np.zeros((vocab_size, 1))\n",
    "        x_s[t][inputs[t]] = 1 # Input character\n",
    "        \n",
    "        (z_s[t], f_s[t], i_s[t],\n",
    "        C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
    "        v_s[t], y_s[t]) = \\\n",
    "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass\n",
    "       \n",
    "            \n",
    "        loss += -np.log(y_s[t][len(targets[t]), 0]) # Loss for at t\n",
    "        \n",
    "    clear_gradients()\n",
    "\n",
    "    dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
    "    dC_next = np.zeros_like(C_s[0]) #dh from the next character\n",
    "\n",
    "    for t in reversed(range(len(inputs))):\n",
    "        # Backward pass\n",
    "        dh_next, dC_next = \\\n",
    "            backward(target = targets[t], dh_next = dh_next,\n",
    "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
    "                     z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
    "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
    "                     y = y_s[t])\n",
    "\n",
    "    clip_gradients()\n",
    "        \n",
    "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]\n",
    "\n",
    "def generate_next_char(h_prev, C_prev, first_char_idx, sentence_length):\n",
    "    x = np.zeros((vocab_size, 1))\n",
    "    x[first_char_idx] = 1\n",
    "\n",
    "    h = h_prev\n",
    "    C = C_prev\n",
    "\n",
    "    indexes = []\n",
    "    \n",
    "    for t in range(sentence_length):\n",
    "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
    "        idx = np.random.choice(range(vocab_size), p=p.ravel())\n",
    "        x = np.zeros((vocab_size, 1))\n",
    "        x[idx] = 1\n",
    "        indexes.append(idx)\n",
    "\n",
    "    return indexes\n",
    "\n",
    "# Update the graph and display a sample output\n",
    "def update_status(inputs, h_prev, C_prev):\n",
    "    #initialized later\n",
    "    global plot_iter, plot_loss\n",
    "    global smooth_loss\n",
    "    \n",
    "    # Get predictions for 200 letters with current model\n",
    "\n",
    "    sample_idx = generate_next_char(h_prev, C_prev, inputs[0], 20)\n",
    "    txt = ''.join(index_to_word[idx] for idx in sample_idx)\n",
    "\n",
    "    # Clear and plot\n",
    "    plt.plot(plot_iter, plot_loss)\n",
    "    display.clear_output(wait=True)\n",
    "    plt.show()\n",
    "\n",
    "    #Print prediction and loss\n",
    "    print(\"----\\n %s \\n----\" % (txt, ))\n",
    "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))\n",
    "    \n",
    "def update_paramters(params = parameters_double):\n",
    "    for p in params.all():\n",
    "        p.m += p.d * p.d # Calculate sum of gradients\n",
    "        #print(learning_rate * dparam)\n",
    "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))\n",
    "        \n",
    "# Exponential average of loss\n",
    "# Initialize to a error of a random model\n",
    "smooth_loss = -np.log(1.0 / vocab_size) * T_steps\n",
    "\n",
    "iteration, pointer = 0, 0\n",
    "\n",
    "# For the graph\n",
    "plot_iter = np.zeros((0))\n",
    "plot_loss = np.zeros((0))\n",
    "\n",
    "# Update the graph and display a sample output\n",
    "def print_status(inputs, h_prev, C_prev):\n",
    "    # Get predictions for 200 letters with current model\n",
    "    sample_idx = generate_next_char(h_prev, C_prev, inputs[0], 20)\n",
    "    txt = ' '.join(index_to_word[idx] for idx in sample_idx)\n",
    "    # Clear and plot\n",
    "    #plt.plot(plot_iter, plot_loss)\n",
    "    #display.clear_output(wait=True)\n",
    "    #plt.show()\n",
    "    #Print prediction and loss\n",
    "    print(\"----\\n %s \\n----\" % (txt, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction at breakpoint:  10\n",
      "----\n",
      " collection end imaginable comprehend sped carolina neither wandering garden treated somewhat compasses boy creating attempt floated disagreeable design planetary seizing \n",
      "----\n",
      "prediction at breakpoint:  20\n",
      "----\n",
      " shots gloomy acid bearing disk brought damages shrug fierce gay recognized tool faded flanks hall weeks steam bed org toledo \n",
      "----\n",
      "prediction at breakpoint:  30\n",
      "----\n",
      " effort tremendous open added bring 000 set hours sweep ends consideration declared attraction denizens child 1 wondered difficulties forehead had \n",
      "----\n",
      "prediction at breakpoint:  40\n",
      "----\n",
      " larger version mechanical sparkling gentlemen 28 kept miserable below travelers applause produced continue latin imagined lapse f visions vegetable notes \n",
      "----\n",
      "prediction at breakpoint:  50\n",
      "----\n",
      " phrase mixed bears thrown example fatality updated cable acoustic gallery purposes change lost is blows similar available badly float chlorate \n",
      "----\n",
      "prediction at breakpoint:  60\n",
      "----\n",
      " silver might institution in precipices moved scartaris momentarily reach fathoms re SENTENCE_END sped laughter slightest journey pickaxes rightly wrong waters \n",
      "----\n",
      "prediction at breakpoint:  70\n",
      "----\n",
      " sandy sneffels including continue last lightning start changing considering teeth asserted banks devil alarm cost running consider entered uses reddish \n",
      "----\n",
      "prediction at breakpoint:  80\n",
      "----\n",
      " 25 persist f license fault torrent with confessed portions chosen cannon panic might entrusted cost wall omitted works lowest remained \n",
      "----\n",
      "prediction at breakpoint:  99\n",
      "----\n",
      " may 29 off that asserted article unhappy eyelids when finest 200 south 10 consent correctness astounding version shelter f and \n",
      "----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1208ae8d0>]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "list_of_breakpoints = [10,20,30,40,50,60,70,80,99]\n",
    "iteration=0\n",
    "plot_loss_inner = []\n",
    "# print('input characters')\n",
    "# print('%s'%\" \".join([index_to_word[x] for x in inputs]))\n",
    "for i in range(100):\n",
    "    if pointer + T_steps >= len(train_data) or iteration == 0:\n",
    "        g_h_prev = np.zeros((H_size, 1))\n",
    "        g_C_prev = np.zeros((H_size, 1))\n",
    "        pointer = 0\n",
    "        inputs = XTrain[:T_steps]\n",
    "        targets = yTrain[:T_steps]\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    loss, g_h_prev, g_C_prev = \\\n",
    "        forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
    "    smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "    if iteration in list_of_breakpoints:\n",
    "        print('prediction at breakpoint: ', iteration)\n",
    "        print_status(inputs, g_h_prev, g_C_prev)\n",
    "\n",
    "    update_paramters()\n",
    "    plot_loss_inner = np.append(plot_loss_inner, [loss])\n",
    "\n",
    "    pointer += T_steps\n",
    "    iteration += 1\n",
    "\n",
    "plt.plot(plot_loss_inner)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Halving hidden units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants and hyper-params\n",
    "H_size = 5 # Size of the hidden layer\n",
    "T_steps = 10\n",
    "# Number of time steps (length of the sequence) used for training\n",
    "learning_rate = .005 # Learning rate\n",
    "weight_sd = 0.1 # Standard deviation of weights for initialization\n",
    "z_size = H_size + vocab_size # Size of concatenate(H, X) vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "# We use random weights with normal distribution (0, weight_sd) for  tanh  activation function \n",
    "# and (0.5, weight_sd) for  sigmoid  activation function.\n",
    "# Biases are initialized to zeros.\n",
    "class Param:\n",
    "    def __init__(self, name, value):\n",
    "        self.name = name\n",
    "        self.v = value #parameter value\n",
    "        self.d = np.zeros_like(value) #derivative\n",
    "        self.m = np.zeros_like(value) #momentum for AdaGrad\n",
    "        \n",
    "class Parameters:\n",
    "    def __init__(self):\n",
    "        self.W_f = Param('W_f', \n",
    "                         np.random.randn(H_size, z_size) * weight_sd + 0.5)\n",
    "        self.b_f = Param('b_f',\n",
    "                         np.zeros((H_size, 1)))\n",
    "\n",
    "        self.W_i = Param('W_i',\n",
    "                         np.random.randn(H_size, z_size) * weight_sd + 0.5)\n",
    "        self.b_i = Param('b_i',\n",
    "                         np.zeros((H_size, 1)))\n",
    "\n",
    "        self.W_C = Param('W_C',\n",
    "                         np.random.randn(H_size, z_size) * weight_sd)\n",
    "        self.b_C = Param('b_C',\n",
    "                         np.zeros((H_size, 1)))\n",
    "\n",
    "        self.W_o = Param('W_o',\n",
    "                         np.random.randn(H_size, z_size) * weight_sd + 0.5)\n",
    "        self.b_o = Param('b_o',\n",
    "                         np.zeros((H_size, 1)))\n",
    "\n",
    "        #For final layer to predict the next character\n",
    "        self.W_v = Param('W_v',\n",
    "                         np.random.randn(vocab_size, H_size) * weight_sd)\n",
    "        self.b_v = Param('b_v',\n",
    "                         np.zeros((vocab_size, 1)))\n",
    "        \n",
    "    def all(self):\n",
    "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
    "               self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
    "        \n",
    "parameters_half = Parameters()\n",
    "\n",
    "def forward(x, h_prev, C_prev, p = parameters_half):\n",
    "    assert x.shape == (vocab_size, 1)\n",
    "    assert h_prev.shape == (H_size, 1)\n",
    "    assert C_prev.shape == (H_size, 1)\n",
    "    \n",
    "    z = np.row_stack((h_prev, x))\n",
    "    f = sigmoid(np.dot(p.W_f.v, z) + p.b_f.v)\n",
    "    i = sigmoid(np.dot(p.W_i.v, z) + p.b_i.v)\n",
    "    C_bar = tanh(np.dot(p.W_C.v, z) + p.b_C.v)\n",
    "\n",
    "    C = f * C_prev + i * C_bar\n",
    "    o = sigmoid(np.dot(p.W_o.v, z) + p.b_o.v)\n",
    "    h = o * tanh(C)\n",
    "\n",
    "    v = np.dot(p.W_v.v, h) + p.b_v.v\n",
    "    y = np.exp(v) / np.sum(np.exp(v)) #softmax\n",
    "\n",
    "    return z, f, i, C_bar, C, o, h, v, y\n",
    "\n",
    "def backward(target, dh_next, dC_next, C_prev,\n",
    "             z, f, i, C_bar, C, o, h, v, y,\n",
    "             p = parameters_half):\n",
    "    \n",
    "    assert z.shape == (vocab_size + H_size, 1)\n",
    "    assert v.shape == (vocab_size, 1)\n",
    "    assert y.shape == (vocab_size, 1)\n",
    "    \n",
    "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
    "        assert param.shape == (H_size, 1)\n",
    "        \n",
    "    dv = np.copy(y)\n",
    "    dv[target] -= 1\n",
    "\n",
    "    p.W_v.d += np.dot(dv, h.T)\n",
    "    p.b_v.d += dv\n",
    "\n",
    "    dh = np.dot(p.W_v.v.T, dv)        \n",
    "    dh += dh_next\n",
    "    do = dh * tanh(C)\n",
    "    do = dsigmoid(o) * do\n",
    "    p.W_o.d += np.dot(do, z.T)\n",
    "    p.b_o.d += do\n",
    "\n",
    "    dC = np.copy(dC_next)\n",
    "    dC += dh * o * dtanh(tanh(C))\n",
    "    dC_bar = dC * i\n",
    "    dC_bar = dtanh(C_bar) * dC_bar\n",
    "    p.W_C.d += np.dot(dC_bar, z.T)\n",
    "    p.b_C.d += dC_bar\n",
    "\n",
    "    di = dC * C_bar\n",
    "    di = dsigmoid(i) * di\n",
    "    p.W_i.d += np.dot(di, z.T)\n",
    "    p.b_i.d += di\n",
    "\n",
    "    df = dC * C_prev\n",
    "    df = dsigmoid(f) * df\n",
    "    p.W_f.d += np.dot(df, z.T)\n",
    "    p.b_f.d += df\n",
    "\n",
    "    dz = (np.dot(p.W_f.v.T, df)\n",
    "         + np.dot(p.W_i.v.T, di)\n",
    "         + np.dot(p.W_C.v.T, dC_bar)\n",
    "         + np.dot(p.W_o.v.T, do))\n",
    "    dh_prev = dz[:H_size, :]\n",
    "    dC_prev = f * dC\n",
    "    \n",
    "    return dh_prev, dC_prev\n",
    "\n",
    "# Clear gradients before each backward pass\n",
    "def clear_gradients(params = parameters_half):\n",
    "    for p in params.all():\n",
    "        p.d.fill(0)\n",
    "        \n",
    "        \n",
    "# Clip gradients to mitigate exploding gradients\n",
    "def clip_gradients(params = parameters_half):\n",
    "    for p in params.all():\n",
    "        np.clip(p.d, -1, 1, out=p.d)\n",
    "        \n",
    "def forward_backward(inputs, targets, h_prev, C_prev):\n",
    "    global paramters\n",
    "    \n",
    "    # To store the values for each time step\n",
    "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
    "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
    "    v_s, y_s =  {}, {}\n",
    "    \n",
    "    # Values at t - 1\n",
    "    h_s[-1] = np.copy(h_prev)\n",
    "    C_s[-1] = np.copy(C_prev)\n",
    "    \n",
    "    loss = 0\n",
    "    # Loop through time steps\n",
    "    for t in range(len(inputs)):\n",
    "        x_s[t] = np.zeros((vocab_size, 1))\n",
    "        x_s[t][inputs[t]] = 1 # Input character\n",
    "        \n",
    "        (z_s[t], f_s[t], i_s[t],\n",
    "        C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
    "        v_s[t], y_s[t]) = \\\n",
    "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass\n",
    "       \n",
    "            \n",
    "        loss += -np.log(y_s[t][len(targets[t]), 0]) # Loss for at t\n",
    "        \n",
    "    clear_gradients()\n",
    "\n",
    "    dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
    "    dC_next = np.zeros_like(C_s[0]) #dh from the next character\n",
    "\n",
    "    for t in reversed(range(len(inputs))):\n",
    "        # Backward pass\n",
    "        dh_next, dC_next = \\\n",
    "            backward(target = targets[t], dh_next = dh_next,\n",
    "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
    "                     z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
    "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
    "                     y = y_s[t])\n",
    "\n",
    "    clip_gradients()\n",
    "        \n",
    "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]\n",
    "\n",
    "def generate_next_char(h_prev, C_prev, first_char_idx, sentence_length):\n",
    "    x = np.zeros((vocab_size, 1))\n",
    "    x[first_char_idx] = 1\n",
    "\n",
    "    h = h_prev\n",
    "    C = C_prev\n",
    "\n",
    "    indexes = []\n",
    "    \n",
    "    for t in range(sentence_length):\n",
    "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
    "        idx = np.random.choice(range(vocab_size), p=p.ravel())\n",
    "        x = np.zeros((vocab_size, 1))\n",
    "        x[idx] = 1\n",
    "        indexes.append(idx)\n",
    "\n",
    "    return indexes\n",
    "\n",
    "# Update the graph and display a sample output\n",
    "def update_status(inputs, h_prev, C_prev):\n",
    "    #initialized later\n",
    "    global plot_iter, plot_loss\n",
    "    global smooth_loss\n",
    "    \n",
    "    # Get predictions for 200 letters with current model\n",
    "\n",
    "    sample_idx = generate_next_char(h_prev, C_prev, inputs[0], 20)\n",
    "    txt = ''.join(index_to_word[idx] for idx in sample_idx)\n",
    "\n",
    "    # Clear and plot\n",
    "    plt.plot(plot_iter, plot_loss)\n",
    "    display.clear_output(wait=True)\n",
    "    plt.show()\n",
    "\n",
    "    #Print prediction and loss\n",
    "    print(\"----\\n %s \\n----\" % (txt, ))\n",
    "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))\n",
    "    \n",
    "def update_paramters(params = parameters_half):\n",
    "    for p in params.all():\n",
    "        p.m += p.d * p.d # Calculate sum of gradients\n",
    "        #print(learning_rate * dparam)\n",
    "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))\n",
    "        \n",
    "# Exponential average of loss\n",
    "# Initialize to a error of a random model\n",
    "smooth_loss = -np.log(1.0 / vocab_size) * T_steps\n",
    "\n",
    "iteration, pointer = 0, 0\n",
    "\n",
    "# For the graph\n",
    "plot_iter = np.zeros((0))\n",
    "plot_loss = np.zeros((0))\n",
    "\n",
    "# Update the graph and display a sample output\n",
    "def print_status(inputs, h_prev, C_prev):\n",
    "    # Get predictions for 200 letters with current model\n",
    "    sample_idx = generate_next_char(h_prev, C_prev, inputs[0], 20)\n",
    "    txt = ' '.join(index_to_word[idx] for idx in sample_idx)\n",
    "    # Clear and plot\n",
    "    #plt.plot(plot_iter, plot_loss)\n",
    "    #display.clear_output(wait=True)\n",
    "    #plt.show()\n",
    "    #Print prediction and loss\n",
    "    print(\"----\\n %s \\n----\" % (txt, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction at breakpoint:  10\n",
      "----\n",
      " humors reappeared decidedly granitic glory distribute resembled scandinavian dying checked electronic inches crushed stage means seventeen tear not seconds friends \n",
      "----\n",
      "prediction at breakpoint:  20\n",
      "----\n",
      " stretched compose deprived count merry searched depths take color longer donate chamber wind b flight noticed turf contradiction resolution equally \n",
      "----\n",
      "prediction at breakpoint:  30\n",
      "----\n",
      " badly reported task active solution indignant SENTENCE_END federal hiding admit institute contains flight columbiad dazzled spark hillisborough asleep sped faintest \n",
      "----\n",
      "prediction at breakpoint:  40\n",
      "----\n",
      " rough calm brings pity sought mile literally mahomet passenger class assemblage wire ebooks limbs importance conditions conviction precipitated forward tore \n",
      "----\n",
      "prediction at breakpoint:  50\n",
      "----\n",
      " warned prospect tear dollars people hearty compared remain arne answered stray others readable twice given 19 bundles rid 25 match \n",
      "----\n",
      "prediction at breakpoint:  60\n",
      "----\n",
      " 10 dining eighty illustrious observations related chauffeurs fail muttered getting revolvers saturated undertaken cessation conceived imposed result walks puzzling set \n",
      "----\n",
      "prediction at breakpoint:  70\n",
      "----\n",
      " disclaimer lessons guide rejoined detonation slightest conjecture firmly note able wrath swim presence separated albany spot coal north fired colored \n",
      "----\n",
      "prediction at breakpoint:  80\n",
      "----\n",
      " passes bad blomsberry 1219 cultivated pleasure antediluvian alter decrease 16 devotion instance restored ladders neptune equipment lightning extended creator shudder \n",
      "----\n",
      "prediction at breakpoint:  99\n",
      "----\n",
      " into available nights initiatory animation zero happy awaiting deluge caused diving resumed motionless capable tuesday susquehanna crossing desperate does snow \n",
      "----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x120c7a780>]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_of_breakpoints = [10,20,30,40,50,60,70,80,99]\n",
    "iteration=0\n",
    "plot_loss_inner = []\n",
    "# print('input characters')\n",
    "# print('%s'%\" \".join([index_to_word[x] for x in inputs]))\n",
    "for i in range(100):\n",
    "    if pointer + T_steps >= len(train_data) or iteration == 0:\n",
    "        g_h_prev = np.zeros((H_size, 1))\n",
    "        g_C_prev = np.zeros((H_size, 1))\n",
    "        pointer = 0\n",
    "        inputs = XTrain[:T_steps]\n",
    "        targets = yTrain[:T_steps]\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    loss, g_h_prev, g_C_prev = \\\n",
    "        forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
    "    smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "    if iteration in list_of_breakpoints:\n",
    "        print('prediction at breakpoint: ', iteration)\n",
    "        print_status(inputs, g_h_prev, g_C_prev)\n",
    "\n",
    "    update_paramters()\n",
    "    plot_loss_inner = np.append(plot_loss_inner, [loss])\n",
    "\n",
    "    pointer += T_steps\n",
    "    iteration += 1\n",
    "\n",
    "plt.plot(plot_loss_inner)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation \n",
    "\n",
    "## Doubling hidden units\n",
    "\n",
    "- Processing time increased\n",
    "\n",
    "- Initially loss decreased to a lower point then increased\n",
    "\n",
    "- word prediction was not good for initial epochs but I hope it will eventually improve with epoch\n",
    "\n",
    "## Halving hidden units\n",
    "\n",
    "- Processing time decreased\n",
    "\n",
    "- loss was lower than other two\n",
    "\n",
    "- character prediction improved "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence length: Try doubling and halving your length of sequence that feeds into the network. And after training, plot the training loss vs the number of training epochs, and show the text sampling results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction at breakpoint:  10\n",
      "----\n",
      " top summit fill mystery moral gravity permission clock redistributing catastrophe hansbach region risk consider miss vii permitted won high destroyed \n",
      "----\n",
      "prediction at breakpoint:  20\n",
      "----\n",
      " pole each leading 2 pencil portion writing fantastic atmospheres once change observatory francs high tenacity highly overcome amid 25 superb \n",
      "----\n",
      "prediction at breakpoint:  30\n",
      "----\n",
      " eagles imagination approve castle phenomenon compact www solely tenacity work accordingly examine northwest initial lighting contracted neutral glance summit regularly \n",
      "----\n",
      "prediction at breakpoint:  40\n",
      "----\n",
      " knocked 24 tomb course nodded xx painful yourselves empty formidable humphry luminous however peculiarly packed primitive expecting turn plan still \n",
      "----\n",
      "prediction at breakpoint:  50\n",
      "----\n",
      " maps hundred across intelligent recovered weigh humphry machinery sealed 150 signature which gaping inert driver attractive cared wretched road left \n",
      "----\n",
      "prediction at breakpoint:  60\n",
      "----\n",
      " federal motions murmur earthly aside hopes at mildly age soft captured canadian envelope waves pole channel explained condensed take back \n",
      "----\n",
      "prediction at breakpoint:  70\n",
      "----\n",
      " degree fiercely headlong bottles pitch unheard injured find screen brought error prospect novel arms status electronically speedily consideration sandstone successful \n",
      "----\n",
      "prediction at breakpoint:  80\n",
      "----\n",
      " ascii bold millions 35 after produce 9 extreme sixty shoulders restrictions eruption personage betrayed obeyed become threatened chose warmly something \n",
      "----\n",
      "prediction at breakpoint:  99\n",
      "----\n",
      " gardar round office 6th perpendicular opportunity wolcott money centrifugal requires feverish devoted verdure fleet launched banquet clasping 8 they obscure \n",
      "----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1210e7a20>]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Doubling\n",
    "\n",
    "\n",
    "T_steps_double = T_steps * 2 \n",
    "parameters = Parameters()\n",
    "list_of_breakpoints = [10,20,30,40,50,60,70,80,99]\n",
    "iteration=0\n",
    "plot_loss_inner = []\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    if pointer + T_steps_double >= len(train_data) or iteration == 0:\n",
    "        g_h_prev = np.zeros((H_size, 1))\n",
    "        g_C_prev = np.zeros((H_size, 1))\n",
    "        pointer = 0\n",
    "    inputs = XTrain[:T_steps_double]\n",
    "    targets = yTrain[:T_steps_double]\n",
    "    \n",
    "\n",
    "    loss, g_h_prev, g_C_prev = \\\n",
    "        forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
    "    smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "    if iteration in list_of_breakpoints:\n",
    "        print('prediction at breakpoint: ', iteration)\n",
    "        print_status(inputs, g_h_prev, g_C_prev)\n",
    "\n",
    "    update_paramters()\n",
    "    plot_loss_inner = np.append(plot_loss_inner, [loss])\n",
    "\n",
    "    pointer += T_steps_double\n",
    "    iteration += 1\n",
    "\n",
    "plt.plot(plot_loss_inner)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction at breakpoint:  10\n",
      "----\n",
      " all distant elphinstone fiery informed being audience theories eagerness frail falls sloping pronounced who performances mad successful impetus deal reduced \n",
      "----\n",
      "prediction at breakpoint:  20\n",
      "----\n",
      " resembled illness correctness drank morrow land goes beds beach deaden supports irradiation 7 steadily canada erie 90 requiring restore locality \n",
      "----\n",
      "prediction at breakpoint:  30\n",
      "----\n",
      " anguish crushed covering astounding person 5 blue birth meat landed terrible fixed schiedam seminoles enclosure doubled carved vast profound her \n",
      "----\n",
      "prediction at breakpoint:  40\n",
      "----\n",
      " entered reserved persist talking conceal wonderful castle lack 8 assistants approaches heaps cylindro 11th burnt port rations monstrous consisting individual \n",
      "----\n",
      "prediction at breakpoint:  50\n",
      "----\n",
      " iceland subterraneous concept telescope safe net vain darting reality maneuver belongs arise sixty safely 9 city watched hunter operation july \n",
      "----\n",
      "prediction at breakpoint:  60\n",
      "----\n",
      " save outline pine situated cosmical optical go construct poor learn northern conflagration infernal circumference desolate production giants p magnifying volcano \n",
      "----\n",
      "prediction at breakpoint:  70\n",
      "----\n",
      " island submerged dream reappear citizens significant consulted doubt delivered comprehended lapse runic returning denouement abysses faces endured degree burn peacefully \n",
      "----\n",
      "prediction at breakpoint:  80\n",
      "----\n",
      " added silence fatiguing commanded mail banquet tight tried windings driver treading traversed rapid spaces amazement desolate slopes engines fair cataract \n",
      "----\n",
      "prediction at breakpoint:  99\n",
      "----\n",
      " better arkansas mountains show single 28 bewildering harmless imperceptible people rays arrived throw affected amiable savage insensate deceived mountainous shepherd \n",
      "----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x120a4e438>]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Halving\n",
    "\n",
    "\n",
    "T_steps_half = T_steps // 2 \n",
    "parameters = Parameters()\n",
    "list_of_breakpoints = [10,20,30,40,50,60,70,80,99]\n",
    "iteration=0\n",
    "plot_loss_inner = []\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    if pointer + T_steps_half >= len(train_data) or iteration == 0:\n",
    "        g_h_prev = np.zeros((H_size, 1))\n",
    "        g_C_prev = np.zeros((H_size, 1))\n",
    "        pointer = 0\n",
    "    inputs = XTrain[:T_steps_half]\n",
    "    targets = yTrain[:T_steps_half]\n",
    "    \n",
    "\n",
    "    loss, g_h_prev, g_C_prev = \\\n",
    "        forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
    "    smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "    if iteration in list_of_breakpoints:\n",
    "        print('prediction at breakpoint: ', iteration)\n",
    "        print_status(inputs, g_h_prev, g_C_prev)\n",
    "\n",
    "    update_paramters()\n",
    "    plot_loss_inner = np.append(plot_loss_inner, [loss])\n",
    "\n",
    "    pointer += T_steps_double\n",
    "    iteration += 1\n",
    "\n",
    "plt.plot(plot_loss_inner)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation\n",
    "\n",
    "## doubling sequence length\n",
    "\n",
    "- Loss did not decrease much than previous graph\n",
    "\n",
    "- processing time increased\n",
    "\n",
    "\n",
    "\n",
    "## halving sequence length\n",
    "\n",
    "- Loss became much low \n",
    "\n",
    "- processing time decreased\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
